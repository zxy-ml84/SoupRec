Response to Review 4: 

Thank you for your comments.
>> Weakness (Overlapping users): There seems to be a misunderstanding. First, please note that in the literature,  MDR encompasses several scenarios, including overlapping and non-overlapping users and items across different domains - e.g. see [6,7,8]. 
Our AdapterSoup model, does not require overlapping users but naturally can be applied in the case of (small or large) overlapping users across the domains. In fact, there is 8.3% overlap of users across the used datasets so this exactly covers the case mentioned by the reviewer namely “user behaviours are highly domain-specific and lack sufficient overlap”. In our evaluation, we report the performance of our method not only on the overlapping users but also all users within the target domain.
Our approach l does of course directly align with the general  MDR scope since it naturally aims to learn universal item representations that incorporate multi-modal semantics across multiple domains. Moreover, using multi-modal data is proven to be more effective for recommendation tasks than using only IDs, as shown in [9].

>> Weakness (Methodology & Code release): It appears that the reviewer has missed some details already provided in the paper. Indeed, we have detailed the hyper-parameters in Section 3.3 and described in  Section 4.1 our training process, including the use of an early-stopping strategy after 50 epochs without improvement.
To facilitate the reproducibility of our approach, we have provided our source code along with the experimental setup in an anonymous GitHub repository (see beginning of our rebuttal response). However, note that the call for papers does not require the release of code during submission. 
>> Weakness (Efficiency of the adapter):  There seems to be a misunderstanding in relation to our use of “computational complexity”. In fact, in Section 2.1, we argued that the shift from cross-domain recommendation to multi-domain recommendation “motivates the need to manage computational complexity while catering to recommendation platforms that span numerous domains, with each domain requiring a specific modelling to capture diverse user behaviours.”  This referred to the need to deploy an effective universal recommendation model that generalises to multiple different target domains. We will tidy up the sentence to avoid confusing it with the system’s efficiency.
However, in relation to efficiency per-see note that the complexity of the used GNN adapter is O(2l_{\alpha}|E|d/B) (the graph convolution operation), where l_{\alpha} is the layer number, E is the number of edges, d is the embedding size, and B is the batch size. This adapter actually has a high efficiency since it does not introduce any learnable weighted matrices when transforming the extracted user/item embeddings into the target domain. We will clarify the issue in the paper.

>> Weakness (Adding a Diagram):
We agree that a diagram could help; paper length constraint permitting, we will try to add one, if possible.
